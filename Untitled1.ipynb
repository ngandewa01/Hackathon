{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "9bff6c46-1e3a-420f-947c-302f4d2245c0",
      "metadata": {
        "id": "9bff6c46-1e3a-420f-947c-302f4d2245c0",
        "outputId": "6164a2b6-75c9-4e95-cf67-3c9e6c67fffa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Qualcomm-DL-Hackathon' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Prashant-AV/Qualcomm-DL-Hackathon.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "9b6d7310-38c8-4940-82b2-673ae2f765f6",
      "metadata": {
        "id": "9b6d7310-38c8-4940-82b2-673ae2f765f6"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "8fed7b0b-dcb5-4d3b-b30b-c1c797029de2",
      "metadata": {
        "id": "8fed7b0b-dcb5-4d3b-b30b-c1c797029de2",
        "outputId": "1e632aa2-be6d-4499-c2d1-3fccc6cad25b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents extracted to /content/train\n",
            "Data from /content/train/images part-1 and /content/train/images part-2 has been combined into /content/train, and the original folders have been deleted.\n"
          ]
        }
      ],
      "source": [
        "extract_dir = \"/content/train\"\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Open and extract the zip file\n",
        "with zipfile.ZipFile(\"/content/Qualcomm-DL-Hackathon/train/images part-1.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "with zipfile.ZipFile(\"/content/Qualcomm-DL-Hackathon/train/images part-2.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(f\"Contents extracted to {extract_dir}\")\n",
        "\n",
        "def combine_and_delete_folders(folder1, folder2, destination_folder):\n",
        "    os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "    # Function to copy files from a folder to the destination\n",
        "    def copy_files(source_folder):\n",
        "        for item in os.listdir(source_folder):\n",
        "            source_path = os.path.join(source_folder, item)\n",
        "            destination_path = os.path.join(destination_folder, item)\n",
        "\n",
        "            # Check if it's a file or a folder\n",
        "            if os.path.isfile(source_path):\n",
        "                shutil.copy2(source_path, destination_path)  # Copy file\n",
        "            elif os.path.isdir(source_path):\n",
        "                # Copy directories recursively\n",
        "                shutil.copytree(source_path, destination_path, dirs_exist_ok=True)\n",
        "\n",
        "    # Copy files from both folders\n",
        "    copy_files(folder1)\n",
        "    copy_files(folder2)\n",
        "\n",
        "    # Delete the original folders\n",
        "    shutil.rmtree(folder1)\n",
        "    shutil.rmtree(folder2)\n",
        "\n",
        "    print(f\"Data from {folder1} and {folder2} has been combined into {destination_folder}, and the original folders have been deleted.\")\n",
        "\n",
        "\n",
        "folder1 = '/content/train/images part-1'\n",
        "folder2 = '/content/train/images part-2'\n",
        "destination_folder = '/content/train'\n",
        "\n",
        "combine_and_delete_folders(folder1, folder2, destination_folder)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "45204e0e-f8b5-4ebb-a22a-f43f081ae854",
      "metadata": {
        "id": "45204e0e-f8b5-4ebb-a22a-f43f081ae854",
        "outputId": "4b2d6700-3ff0-4833-e9fe-a895638a930a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data copied\n"
          ]
        }
      ],
      "source": [
        "train_folder = '/content/train'\n",
        "test_folder = '/content/test'\n",
        "emergency_folder = os.path.join(train_folder, 'emergency')\n",
        "non_emergency_folder = os.path.join(train_folder, 'non_emergency')\n",
        "csv_file_train = '/content/Qualcomm-DL-Hackathon/train/train.csv'\n",
        "csv_file_test = '/content/Qualcomm-DL-Hackathon/test.csv'\n",
        "os.makedirs(test_folder, exist_ok=True)\n",
        "os.makedirs(emergency_folder, exist_ok=True)\n",
        "os.makedirs(non_emergency_folder, exist_ok=True)\n",
        "\n",
        "data_test =pd.read_csv(csv_file_test)\n",
        "for index, row in data_test.iterrows():\n",
        "    image_name = row['image_names']\n",
        "    source_path = os.path.join(train_folder, image_name)\n",
        "    destination_path = os.path.join(test_folder, image_name)\n",
        "    if os.path.exists(source_path):\n",
        "        shutil.move(source_path, destination_path)\n",
        "\n",
        "data_train = pd.read_csv(csv_file_train)\n",
        "for index, row in data_train.iterrows():\n",
        "    image_name = row['image_names']\n",
        "    label = row['emergency_or_not']\n",
        "    source_path = os.path.join(train_folder, image_name)\n",
        "    label = row['emergency_or_not']\n",
        "    src_path = os.path.join(train_folder, image_name)\n",
        "    if os.path.exists(src_path):\n",
        "        if label == 1:\n",
        "            destination_path = os.path.join(emergency_folder, image_name)\n",
        "        elif label == 0:\n",
        "            destination_path = os.path.join(non_emergency_folder, image_name)\n",
        "        else:\n",
        "            print(f\"Invalid label for image {image_name}\")\n",
        "            continue\n",
        "        shutil.copy2(src_path, destination_path)\n",
        "    else:\n",
        "        print(f\"Source file not found: {src_path}\")\n",
        "print(\"Data copied\")\n",
        "\n",
        "for item in os.listdir(train_folder):\n",
        "    item_path = os.path.join(train_folder, item)\n",
        "    if os.path.isdir(item_path) and item not in ['emergency', 'non_emergency']:\n",
        "        shutil.rmtree(item_path)\n",
        "    elif os.path.isfile(item_path):\n",
        "        os.remove(item_path)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "dataset = datasets.ImageFolder(root='/content/train', transform=transform)\n",
        "\n",
        "imgs = torch.stack([img_t for img_t, _ in dataset], dim=3)\n",
        "imgs.shape\n",
        "\n",
        "mean = imgs.view(3, -1).mean(dim=1)\n",
        "std = imgs.view(3, -1).std(dim=1)\n",
        "print(\"Mean:\",mean)\n",
        "print(\"standard deviation:\",std)"
      ],
      "metadata": {
        "id": "u5X23yhRkuW9",
        "outputId": "011b6ea0-3c1d-4101-bdf7-33364ba1ba63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "u5X23yhRkuW9",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: tensor([0.4371, 0.4252, 0.4137])\n",
            "standard deviation: tensor([0.2791, 0.2776, 0.2837])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    #transforms.Normalize(mean= mean, std= std),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "])"
      ],
      "metadata": {
        "id": "2a87DezvoRvh"
      },
      "id": "2a87DezvoRvh",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(root='/content/train', transform=transform)\n"
      ],
      "metadata": {
        "id": "dv0XwbRNoVS8"
      },
      "id": "dv0XwbRNoVS8",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n"
      ],
      "metadata": {
        "id": "74MQQqgtorIY"
      },
      "id": "74MQQqgtorIY",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "Ux6DbF1iozoZ"
      },
      "id": "Ux6DbF1iozoZ",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = dataset.classes\n",
        "print(\"classes:\",class_names)"
      ],
      "metadata": {
        "id": "bCRWuj5npGRT",
        "outputId": "d5b74f13-6d77-4832-d668-b42aa5964c04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bCRWuj5npGRT",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classes: ['emergency', 'non_emergency']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fc35eba-0fcd-49f0-96e1-e6a7e7747ded",
      "metadata": {
        "id": "6fc35eba-0fcd-49f0-96e1-e6a7e7747ded"
      },
      "source": [
        "since URL, phone, menu item does not give information about data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "09f24268-d1b8-44e8-8dfe-3ad4b3a80a0d",
      "metadata": {
        "id": "09f24268-d1b8-44e8-8dfe-3ad4b3a80a0d"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(CNN,self).__init__()\n",
        "      # 3*128*128\n",
        "      self.conv1 = nn.Conv2d(3,32,kernel_size =3, stride =1, padding=1)\n",
        "      self.batchnorm1 = nn.BatchNorm2d(32)\n",
        "      self.conv2 = nn.Conv2d(32,64,kernel_size =3, stride =1, padding=1)\n",
        "      self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "      self.conv3 = nn.Conv2d(64,128,kernel_size =3, stride =1, padding=1)\n",
        "      self.batchnorm3 = nn.BatchNorm2d(128)\n",
        "      self.conv4 = nn.Conv2d(128,256,kernel_size =3, stride =1, padding=1)\n",
        "      self.batchnorm4 = nn.BatchNorm2d(256)\n",
        "      self.conv5 =  nn.Conv2d(256,512,kernel_size =3, stride =1, padding=1)\n",
        "      self.batchnorm5 = nn.BatchNorm2d(512)\n",
        "      self.pool = nn.MaxPool2d(kernel_size =2, stride =2)\n",
        "      self.fc1  = nn.Linear(512*4*4, 64)\n",
        "      self.fc2 = nn.Linear(64,16)\n",
        "      self.fc3 = nn.Linear(16,2)\n",
        "      self.relu = nn.LeakyReLU()\n",
        "      self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = self.pool(self.relu(self.batchnorm1(self.conv1(x)))) #32*64*64\n",
        "      #print(\"Shape after conv1 and pool:\", x.shape)\n",
        "      x = self.pool(self.relu(self.batchnorm2(self.conv2(x)))) #64*32*32\n",
        "      #print(\"Shape after conv2 and pool:\", x.shape)\n",
        "      x = self.pool(self.relu(self.batchnorm3(self.conv3(x)))) #128*16*16\n",
        "      #print(\"Shape after conv3 and pool:\", x.shape)\n",
        "      x = self.pool(self.relu(self.batchnorm4(self.conv4(x)))) #256*8*8\n",
        "      #print(\"Shape after conv4 and pool:\", x.shape)\n",
        "      x = self.pool(self.relu(self.batchnorm5(self.conv5(x)))) #512*4*4\n",
        "      #print(\"Shape after conv5 and pool:\", x.shape)\n",
        "      x = x.view(x.size(0),-1)\n",
        "      #print(\"Shape after flattening:\", x.shape)\n",
        "      x = self.relu(self.fc1(x))\n",
        "      x = self.dropout(x)\n",
        "      x = self.relu(self.fc2(x))\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc3(x)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "9ee1f4a4-f389-43c0-b990-0e73329e474d",
      "metadata": {
        "id": "9ee1f4a4-f389-43c0-b990-0e73329e474d",
        "outputId": "f2202f9f-35aa-4a57-e966-2bc25e62a60f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on device cpu.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batchnorm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batchnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batchnorm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batchnorm4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batchnorm5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=8192, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
              "  (fc3): Linear(in_features=16, out_features=2, bias=True)\n",
              "  (relu): LeakyReLU(negative_slope=0.01)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "device = (torch.device('cuda') if torch.cuda.is_available()\n",
        "          else torch.device('cpu'))\n",
        "print(f\"Training on device {device}.\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {train_loss/len(train_loader):.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
        "print(\"Training Completed\")"
      ],
      "metadata": {
        "id": "ZpMrOxXd0sas",
        "outputId": "990869ab-80ed-4c35-9e93-1e9b3bc4834b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZpMrOxXd0sas",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Loss: 0.5689, Accuracy: 70.66%\n",
            "Epoch [2/30], Loss: 0.4792, Accuracy: 77.69%\n",
            "Epoch [3/30], Loss: 0.4427, Accuracy: 81.25%\n",
            "Epoch [4/30], Loss: 0.3947, Accuracy: 82.90%\n",
            "Epoch [5/30], Loss: 0.3874, Accuracy: 82.73%\n",
            "Epoch [6/30], Loss: 0.3440, Accuracy: 85.24%\n",
            "Epoch [7/30], Loss: 0.3293, Accuracy: 86.37%\n",
            "Epoch [8/30], Loss: 0.3151, Accuracy: 85.59%\n",
            "Epoch [9/30], Loss: 0.2919, Accuracy: 87.93%\n",
            "Epoch [10/30], Loss: 0.2892, Accuracy: 88.02%\n",
            "Epoch [11/30], Loss: 0.2919, Accuracy: 89.15%\n",
            "Epoch [12/30], Loss: 0.2743, Accuracy: 89.24%\n",
            "Epoch [13/30], Loss: 0.2638, Accuracy: 90.19%\n",
            "Epoch [14/30], Loss: 0.2589, Accuracy: 90.10%\n",
            "Epoch [15/30], Loss: 0.2504, Accuracy: 90.36%\n",
            "Epoch [16/30], Loss: 0.2396, Accuracy: 90.10%\n",
            "Epoch [17/30], Loss: 0.2372, Accuracy: 90.28%\n",
            "Epoch [18/30], Loss: 0.2068, Accuracy: 91.93%\n",
            "Epoch [19/30], Loss: 0.2077, Accuracy: 91.58%\n",
            "Epoch [20/30], Loss: 0.2043, Accuracy: 91.84%\n",
            "Epoch [21/30], Loss: 0.2166, Accuracy: 91.41%\n",
            "Epoch [22/30], Loss: 0.1844, Accuracy: 93.40%\n",
            "Epoch [23/30], Loss: 0.2380, Accuracy: 91.15%\n",
            "Epoch [24/30], Loss: 0.1794, Accuracy: 93.06%\n",
            "Epoch [25/30], Loss: 0.1669, Accuracy: 93.84%\n",
            "Epoch [26/30], Loss: 0.1585, Accuracy: 93.40%\n",
            "Epoch [27/30], Loss: 0.1433, Accuracy: 94.27%\n",
            "Epoch [28/30], Loss: 0.1440, Accuracy: 94.79%\n",
            "Epoch [29/30], Loss: 0.1285, Accuracy: 94.79%\n",
            "Epoch [30/30], Loss: 0.1399, Accuracy: 94.79%\n",
            "Training Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "val_correct = 0\n",
        "val_total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        val_total += labels.size(0)\n",
        "        val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "val_accuracy = 100 * val_correct / val_total\n",
        "print(f'Validation Accuracy: {val_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "tyL5wqZCNk86",
        "outputId": "d02ab2a0-4bec-4c3a-d863-14d71a2ba30d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tyL5wqZCNk86",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 80.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_test_accuracy = 0.0  # To track the best test accuracy\n",
        "save_path = \"best_model.pth\"  # File to save the best model\n",
        "patience = 5  # Number of evaluations to wait before stopping\n",
        "no_improvement = 0  # Counter for no improvement\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Training loop\n",
        "    for images, labels in train_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {epoch_accuracy:.2f}%\")\n",
        "\n",
        "    # Evaluate test accuracy every 3rd epoch\n",
        "    if (epoch + 1) % 1== 0:\n",
        "        model.eval()  # Set model to evaluation mode\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "              images, labels = images.to(device), labels.to(device)\n",
        "              outputs = model(images)\n",
        "              _, predicted = torch.max(outputs, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_accuracy = 100 * correct / total\n",
        "        print(f\"Epoch {epoch+1}, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "        # Check for improvement\n",
        "        if test_accuracy > best_test_accuracy:\n",
        "            best_test_accuracy = test_accuracy\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"Model saved at epoch {epoch+1} with test accuracy: {best_test_accuracy:.2f}%\")\n",
        "            no_improvement = 0  # Reset counter\n",
        "        else:\n",
        "            no_improvement += 1\n",
        "            print(f\"No improvement for {no_improvement} evaluations.\")\n",
        "\n",
        "        # Stop training if no improvement for `patience` evaluations\n",
        "        if no_improvement >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "print(f\"Training complete. Best Test Accuracy: {best_test_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "UgoYE2BynIlz",
        "outputId": "384fcb59-fb3b-40d8-9e52-4e63024ba0e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UgoYE2BynIlz",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.1423, Train Accuracy: 94.79%\n",
            "Epoch 1, Test Accuracy: 85.63%\n",
            "Model saved at epoch 1 with test accuracy: 85.63%\n",
            "Epoch 2, Loss: 0.1306, Train Accuracy: 94.79%\n",
            "Epoch 2, Test Accuracy: 86.64%\n",
            "Model saved at epoch 2 with test accuracy: 86.64%\n",
            "Epoch 3, Loss: 0.1527, Train Accuracy: 94.79%\n",
            "Epoch 3, Test Accuracy: 86.64%\n",
            "No improvement for 1 evaluations.\n",
            "Epoch 4, Loss: 0.1013, Train Accuracy: 94.79%\n",
            "Epoch 4, Test Accuracy: 85.02%\n",
            "No improvement for 2 evaluations.\n",
            "Epoch 5, Loss: 0.1204, Train Accuracy: 94.79%\n",
            "Epoch 5, Test Accuracy: 72.87%\n",
            "No improvement for 3 evaluations.\n",
            "Epoch 6, Loss: 0.1114, Train Accuracy: 94.79%\n",
            "Epoch 6, Test Accuracy: 85.63%\n",
            "No improvement for 4 evaluations.\n",
            "Epoch 7, Loss: 0.0994, Train Accuracy: 94.79%\n",
            "Epoch 7, Test Accuracy: 80.77%\n",
            "No improvement for 5 evaluations.\n",
            "Early stopping triggered.\n",
            "Training complete. Best Test Accuracy: 86.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n",
        ")"
      ],
      "metadata": {
        "id": "1Dh_Hvo1RMWn",
        "outputId": "e128a38e-ec04-4deb-ec7d-7cf6f84010e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1Dh_Hvo1RMWn",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-95-30a3f1b9e587>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"best_model.pth\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = '/content/Qualcomm-DL-Hackathon/test.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "df['prediction']= None"
      ],
      "metadata": {
        "id": "wtyFq3g1RwtX"
      },
      "id": "wtyFq3g1RwtX",
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['emergency', 'non_emergency']\n",
        "test_folder = '/content/test'\n",
        "for index, row in df.iterrows():\n",
        "    image_name = row['image_names']\n",
        "    image_path = os.path.join(test_folder, image_name)\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image)\n",
        "    image = image.unsqueeze(0)\n",
        "    image = image.to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        predicted_class = class_names[predicted.item()]\n",
        "        df.at[index, 'prediction'] = predicted_class"
      ],
      "metadata": {
        "id": "JOdzxNGZSPJt"
      },
      "id": "JOdzxNGZSPJt",
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_csv_path = '/content/submission.csv'\n",
        "df.to_csv(updated_csv_path, index=False)\n",
        "print(f\"Prediction Saved to {updated_csv_path}\")"
      ],
      "metadata": {
        "id": "vyktsSDPTA21",
        "outputId": "3c702189-35da-44c7-c82b-802906964166",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vyktsSDPTA21",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction Saved to /content/submission.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}